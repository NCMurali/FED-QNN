{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8QhD2lNlzIs",
        "outputId": "603f0e0a-9f29-48a0-ae64-eccb3b2b4e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: -O: command not found\n",
            "--2025-11-15 07:39:04--  https://www.dropbox.com/scl/fi/dwwd3r0gvxaiuq6pjnb9v/NF-ToN-IoT-V2.parquet?rlkey=kwfzpx81rpmahd61r9zkx2ct3\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.85.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.85.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucccad594f4cb7860055239560be.dl.dropboxusercontent.com/cd/0/inline/C1MsHCU9BgnvmMNqRewUIXYp3YuwpjyXAJT4AFsufXrGGuLE_Xvv57sFd7AAE2J3caHxDiy1lD9XLqKipXpKYhElv23LbTthXDe26VFKQpodz9P6v29TXzpaGNZFh8CWTlnpTeoU0qc12L2gdQL-Kc_y/file# [following]\n",
            "--2025-11-15 07:39:05--  https://ucccad594f4cb7860055239560be.dl.dropboxusercontent.com/cd/0/inline/C1MsHCU9BgnvmMNqRewUIXYp3YuwpjyXAJT4AFsufXrGGuLE_Xvv57sFd7AAE2J3caHxDiy1lD9XLqKipXpKYhElv23LbTthXDe26VFKQpodz9P6v29TXzpaGNZFh8CWTlnpTeoU0qc12L2gdQL-Kc_y/file\n",
            "Resolving ucccad594f4cb7860055239560be.dl.dropboxusercontent.com (ucccad594f4cb7860055239560be.dl.dropboxusercontent.com)... 162.125.85.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to ucccad594f4cb7860055239560be.dl.dropboxusercontent.com (ucccad594f4cb7860055239560be.dl.dropboxusercontent.com)|162.125.85.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/C1O7InubEBmlEgwWWBDLY-1EirsgXap3zYr3SEkT3y9d9sSV4P3_Cvw_8k832um8z-co_B5gHekCAolzjOaS5l4Ha-AdzE7H_hiX8HXGt_ZLV1ecTe0WpxgHFlMM0_D2z3aTa-wln_JFvPsvnDGafeKzeF5wvJHxG-qjUY8DTrnfnEI_KYG62-1QB_VKJtOkHrACnQpSqV8Ntbj7avb-D7hYw31WrbW0qa5FSbtdy1-FS-vgbyLvdKgxH1SsFHheixK-2eTW-Q8Ec-0aiSxqVnFzGLIa_9WdevDKAdz6SE8l7ygHQbfbQ48k8XlmGi0OueTfis5O_vx80hy3mvhe3UXwlSmwcruBMnFtemP4Z2k_GNIw5ICEhG_ft-xzm-3TVpo/file [following]\n",
            "--2025-11-15 07:39:06--  https://ucccad594f4cb7860055239560be.dl.dropboxusercontent.com/cd/0/inline2/C1O7InubEBmlEgwWWBDLY-1EirsgXap3zYr3SEkT3y9d9sSV4P3_Cvw_8k832um8z-co_B5gHekCAolzjOaS5l4Ha-AdzE7H_hiX8HXGt_ZLV1ecTe0WpxgHFlMM0_D2z3aTa-wln_JFvPsvnDGafeKzeF5wvJHxG-qjUY8DTrnfnEI_KYG62-1QB_VKJtOkHrACnQpSqV8Ntbj7avb-D7hYw31WrbW0qa5FSbtdy1-FS-vgbyLvdKgxH1SsFHheixK-2eTW-Q8Ec-0aiSxqVnFzGLIa_9WdevDKAdz6SE8l7ygHQbfbQ48k8XlmGi0OueTfis5O_vx80hy3mvhe3UXwlSmwcruBMnFtemP4Z2k_GNIw5ICEhG_ft-xzm-3TVpo/file\n",
            "Reusing existing connection to ucccad594f4cb7860055239560be.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209170339 (199M) [application/octet-stream]\n",
            "Saving to: ‘NF-ToN-IoT-V2.parquet?rlkey=kwfzpx81rpmahd61r9zkx2ct3’\n",
            "\n",
            "NF-ToN-IoT-V2.parqu 100%[===================>] 199.48M  12.9MB/s    in 17s     \n",
            "\n",
            "2025-11-15 07:39:24 (11.5 MB/s) - ‘NF-ToN-IoT-V2.parquet?rlkey=kwfzpx81rpmahd61r9zkx2ct3’ saved [209170339/209170339]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/scl/fi/dwwd3r0gvxaiuq6pjnb9v/NF-ToN-IoT-V2.parquet?rlkey=kwfzpx81rpmahd61r9zkx2ct3&st=lfyqbgbt&dl=0 -O NF-ToN-IoT-V2.parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQJCT9p-zwFx",
        "outputId": "2ebcf119-3163-48ca-b353-96ffad03705c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m934.3/934.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet pennylane torch scikit-learn pandas numpy pyarrow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szAM6zyixXBJ",
        "outputId": "015cd9ef-6a29-437e-bd0f-028ebfa442c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.7.2 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as pnp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from copy import deepcopy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qnm3pXtduYcM",
        "outputId": "d3004fba-ef3e-4d66-d6c2-daf51d45133e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows: 13135881\n",
            "Columns: ['L4_SRC_PORT', 'L4_DST_PORT', 'PROTOCOL', 'L7_PROTO', 'IN_BYTES', 'IN_PKTS', 'OUT_BYTES', 'OUT_PKTS', 'TCP_FLAGS', 'CLIENT_TCP_FLAGS', 'SERVER_TCP_FLAGS', 'FLOW_DURATION_MILLISECONDS', 'DURATION_IN', 'DURATION_OUT', 'MIN_TTL', 'MAX_TTL', 'LONGEST_FLOW_PKT', 'SHORTEST_FLOW_PKT', 'MIN_IP_PKT_LEN', 'MAX_IP_PKT_LEN', 'SRC_TO_DST_SECOND_BYTES', 'DST_TO_SRC_SECOND_BYTES', 'RETRANSMITTED_IN_BYTES', 'RETRANSMITTED_IN_PKTS', 'RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT', 'NUM_PKTS_UP_TO_128_BYTES', 'NUM_PKTS_128_TO_256_BYTES', 'NUM_PKTS_256_TO_512_BYTES', 'NUM_PKTS_512_TO_1024_BYTES', 'NUM_PKTS_1024_TO_1514_BYTES', 'TCP_WIN_MAX_IN', 'TCP_WIN_MAX_OUT', 'ICMP_TYPE', 'ICMP_IPV4_TYPE', 'DNS_QUERY_ID', 'DNS_QUERY_TYPE', 'DNS_TTL_ANSWER', 'FTP_COMMAND_RET_CODE', 'Label', 'Attack']\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3251bc45-8443-491e-9189-f7669dd8864a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>L4_SRC_PORT</th>\n",
              "      <td>49235</td>\n",
              "      <td>49228</td>\n",
              "      <td>0</td>\n",
              "      <td>65317</td>\n",
              "      <td>60766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L4_DST_PORT</th>\n",
              "      <td>4444</td>\n",
              "      <td>1880</td>\n",
              "      <td>0</td>\n",
              "      <td>1900</td>\n",
              "      <td>15600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PROTOCOL</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L7_PROTO</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IN_BYTES</th>\n",
              "      <td>155392</td>\n",
              "      <td>1600</td>\n",
              "      <td>212</td>\n",
              "      <td>165</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IN_PKTS</th>\n",
              "      <td>202</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <td>34552</td>\n",
              "      <td>35741</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <td>149</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <td>24</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SERVER_TCP_FLAGS</th>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLOW_DURATION_MILLISECONDS</th>\n",
              "      <td>4294952</td>\n",
              "      <td>4294952</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DURATION_IN</th>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DURATION_OUT</th>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIN_TTL</th>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAX_TTL</th>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LONGEST_FLOW_PKT</th>\n",
              "      <td>1500</td>\n",
              "      <td>1286</td>\n",
              "      <td>106</td>\n",
              "      <td>165</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SHORTEST_FLOW_PKT</th>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>106</td>\n",
              "      <td>165</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIN_IP_PKT_LEN</th>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAX_IP_PKT_LEN</th>\n",
              "      <td>1500</td>\n",
              "      <td>1286</td>\n",
              "      <td>106</td>\n",
              "      <td>165</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SRC_TO_DST_SECOND_BYTES</th>\n",
              "      <td>155392.0</td>\n",
              "      <td>1600.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DST_TO_SRC_SECOND_BYTES</th>\n",
              "      <td>34552.0</td>\n",
              "      <td>35741.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RETRANSMITTED_IN_BYTES</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RETRANSMITTED_IN_PKTS</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RETRANSMITTED_OUT_BYTES</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RETRANSMITTED_OUT_PKTS</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SRC_TO_DST_AVG_THROUGHPUT</th>\n",
              "      <td>77696000</td>\n",
              "      <td>800000</td>\n",
              "      <td>1696000</td>\n",
              "      <td>1320000</td>\n",
              "      <td>504000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DST_TO_SRC_AVG_THROUGHPUT</th>\n",
              "      <td>17272000</td>\n",
              "      <td>17864000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NUM_PKTS_UP_TO_128_BYTES</th>\n",
              "      <td>56</td>\n",
              "      <td>47</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NUM_PKTS_128_TO_256_BYTES</th>\n",
              "      <td>150</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NUM_PKTS_256_TO_512_BYTES</th>\n",
              "      <td>36</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NUM_PKTS_512_TO_1024_BYTES</th>\n",
              "      <td>14</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
              "      <td>95</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCP_WIN_MAX_IN</th>\n",
              "      <td>45555</td>\n",
              "      <td>16425</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <td>4805</td>\n",
              "      <td>237</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>771</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attack</th>\n",
              "      <td>ransomware</td>\n",
              "      <td>Benign</td>\n",
              "      <td>Benign</td>\n",
              "      <td>Benign</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3251bc45-8443-491e-9189-f7669dd8864a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3251bc45-8443-491e-9189-f7669dd8864a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3251bc45-8443-491e-9189-f7669dd8864a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-35843fe0-41d0-496d-9d26-0e8674c1431b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35843fe0-41d0-496d-9d26-0e8674c1431b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-35843fe0-41d0-496d-9d26-0e8674c1431b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                      0         1        2        3       4\n",
              "L4_SRC_PORT                       49235     49228        0    65317   60766\n",
              "L4_DST_PORT                        4444      1880        0     1900   15600\n",
              "PROTOCOL                              6         6        1       17      17\n",
              "L7_PROTO                            0.0       0.0      0.0      0.0     0.0\n",
              "IN_BYTES                         155392      1600      212      165      63\n",
              "IN_PKTS                             202        40        2        1       1\n",
              "OUT_BYTES                         34552     35741        0        0       0\n",
              "OUT_PKTS                            149        65        0        0       0\n",
              "TCP_FLAGS                            24        24        0        0       0\n",
              "CLIENT_TCP_FLAGS                     24        16        0        0       0\n",
              "SERVER_TCP_FLAGS                     24        24        0        0       0\n",
              "FLOW_DURATION_MILLISECONDS      4294952   4294952        0        0       0\n",
              "DURATION_IN                          15        15        0        0       0\n",
              "DURATION_OUT                         15        15        0        0       0\n",
              "MIN_TTL                             128       128       64        0       0\n",
              "MAX_TTL                             128       128       64        0       0\n",
              "LONGEST_FLOW_PKT                   1500      1286      106      165      63\n",
              "SHORTEST_FLOW_PKT                    40        40      106      165      63\n",
              "MIN_IP_PKT_LEN                       40        40        0        0       0\n",
              "MAX_IP_PKT_LEN                     1500      1286      106      165      63\n",
              "SRC_TO_DST_SECOND_BYTES        155392.0    1600.0    212.0    165.0    63.0\n",
              "DST_TO_SRC_SECOND_BYTES         34552.0   35741.0      0.0      0.0     0.0\n",
              "RETRANSMITTED_IN_BYTES                0         0        0        0       0\n",
              "RETRANSMITTED_IN_PKTS                 0         0        0        0       0\n",
              "RETRANSMITTED_OUT_BYTES               0         0        0        0       0\n",
              "RETRANSMITTED_OUT_PKTS                0         0        0        0       0\n",
              "SRC_TO_DST_AVG_THROUGHPUT      77696000    800000  1696000  1320000  504000\n",
              "DST_TO_SRC_AVG_THROUGHPUT      17272000  17864000        0        0       0\n",
              "NUM_PKTS_UP_TO_128_BYTES             56        47        2        0       1\n",
              "NUM_PKTS_128_TO_256_BYTES           150         3        0        1       0\n",
              "NUM_PKTS_256_TO_512_BYTES            36        30        0        0       0\n",
              "NUM_PKTS_512_TO_1024_BYTES           14        19        0        0       0\n",
              "NUM_PKTS_1024_TO_1514_BYTES          95         6        0        0       0\n",
              "TCP_WIN_MAX_IN                    45555     16425        0        0       0\n",
              "TCP_WIN_MAX_OUT                    4805       237        0        0       0\n",
              "ICMP_TYPE                             0         0      771        0       0\n",
              "ICMP_IPV4_TYPE                        0         0        3        0       0\n",
              "DNS_QUERY_ID                          0         0        0        0       0\n",
              "DNS_QUERY_TYPE                        0         0        0        0       0\n",
              "DNS_TTL_ANSWER                        0         0        0        0       0\n",
              "FTP_COMMAND_RET_CODE                  0         0        0        0       0\n",
              "Label                                 1         0        0        0       0\n",
              "Attack                       ransomware    Benign   Benign   Benign  Benign"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cell 2: load parquet file (update path if needed)\n",
        "# Put your NF-ToN-IoT-v2.parquet in Colab /content or mount Drive and use path.\n",
        "parquet_path = \"/content/NF-ToN-IoT-V2.parquet?rlkey=kwfzpx81rpmahd61r9zkx2ct3\"  # <- update if needed\n",
        "df = pd.read_parquet(parquet_path)\n",
        "\n",
        "# Quick peek\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "df.head().T  # show transpose for readability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G42VVHOoBLQN",
        "outputId": "a587241b-1df8-4f3b-e2ae-540ef79af442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled dataset shape: (100000, 43)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming df is your full NF-TON V2 dataframe\n",
        "train_size = 100_000  # approx. 100k rows for Colab free tier\n",
        "\n",
        "# Stratified sampling to preserve class proportions\n",
        "df_sampled, _ = train_test_split(df, train_size=train_size, stratify=df['Label'], random_state=42)\n",
        "\n",
        "print(\"Sampled dataset shape:\", df_sampled.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwTmxed-BYcV",
        "outputId": "5a0fd311-11fb-4179-aa04-223bef0bd100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaNs per column:\n",
            " L4_SRC_PORT                    0\n",
            "L4_DST_PORT                    0\n",
            "PROTOCOL                       0\n",
            "L7_PROTO                       0\n",
            "IN_BYTES                       0\n",
            "IN_PKTS                        0\n",
            "OUT_BYTES                      0\n",
            "OUT_PKTS                       0\n",
            "TCP_FLAGS                      0\n",
            "CLIENT_TCP_FLAGS               0\n",
            "SERVER_TCP_FLAGS               0\n",
            "FLOW_DURATION_MILLISECONDS     0\n",
            "DURATION_IN                    0\n",
            "DURATION_OUT                   0\n",
            "MIN_TTL                        0\n",
            "MAX_TTL                        0\n",
            "LONGEST_FLOW_PKT               0\n",
            "SHORTEST_FLOW_PKT              0\n",
            "MIN_IP_PKT_LEN                 0\n",
            "MAX_IP_PKT_LEN                 0\n",
            "SRC_TO_DST_SECOND_BYTES        0\n",
            "DST_TO_SRC_SECOND_BYTES        0\n",
            "RETRANSMITTED_IN_BYTES         0\n",
            "RETRANSMITTED_IN_PKTS          0\n",
            "RETRANSMITTED_OUT_BYTES        0\n",
            "RETRANSMITTED_OUT_PKTS         0\n",
            "SRC_TO_DST_AVG_THROUGHPUT      0\n",
            "DST_TO_SRC_AVG_THROUGHPUT      0\n",
            "NUM_PKTS_UP_TO_128_BYTES       0\n",
            "NUM_PKTS_128_TO_256_BYTES      0\n",
            "NUM_PKTS_256_TO_512_BYTES      0\n",
            "NUM_PKTS_512_TO_1024_BYTES     0\n",
            "NUM_PKTS_1024_TO_1514_BYTES    0\n",
            "TCP_WIN_MAX_IN                 0\n",
            "TCP_WIN_MAX_OUT                0\n",
            "ICMP_TYPE                      0\n",
            "ICMP_IPV4_TYPE                 0\n",
            "DNS_QUERY_ID                   0\n",
            "DNS_QUERY_TYPE                 0\n",
            "DNS_TTL_ANSWER                 0\n",
            "FTP_COMMAND_RET_CODE           0\n",
            "Label                          0\n",
            "Attack                         0\n",
            "dtype: int64\n",
            "Shape after removing NaNs/Infs: (100000, 43)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Count NaNs per column\n",
        "print(\"NaNs per column:\\n\", df_sampled.isna().sum())\n",
        "\n",
        "# Replace infinite values with NaN\n",
        "df_sampled.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with NaN (or you can impute)\n",
        "df_sampled.dropna(inplace=True)\n",
        "\n",
        "print(\"Shape after removing NaNs/Infs:\", df_sampled.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MobTWHXSB4HD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X_raw = df_sampled.drop(columns=[\"Label\", \"Attack\"]).values\n",
        "y = df_sampled[\"Label\"].values\n",
        "\n",
        "# Clip values to avoid overflow (optional: adjust percentiles)\n",
        "percentile = 99.9\n",
        "upper_bounds = np.percentile(X_raw, percentile, axis=0)\n",
        "lower_bounds = np.percentile(X_raw, 100 - percentile, axis=0)\n",
        "\n",
        "X_clipped = np.clip(X_raw, lower_bounds, upper_bounds)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ-cpNxhBdYY"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_clipped)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMbX08TqB0Yt",
        "outputId": "9299a9aa-0767-4e6f-dbd0-5b7e3d6edf96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA output shape: (100000, 12)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=12)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(\"PCA output shape:\", X_pca.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbBmVhdJCzNm",
        "outputId": "abbcfe01-bd2e-4897-e37e-aebd50735573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_o3F6zZZCKVP"
      },
      "outputs": [],
      "source": [
        "# Cell 5\n",
        "# Stratified split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Function to move batch to GPU\n",
        "def batch_to_device(batch, device):\n",
        "    X, y = batch\n",
        "    return X.to(device), y.to(device)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
        "                                        torch.tensor(y_train, dtype=torch.long)),\n",
        "                          batch_size=16, shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
        "                                       torch.tensor(y_test, dtype=torch.long)),\n",
        "                         batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2FIA_3HCVe5"
      },
      "outputs": [],
      "source": [
        "# Cell 6\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "classes = np.unique(y_train)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "# Weighted loss\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXGi81vsCXF7"
      },
      "outputs": [],
      "source": [
        "# Cell 7\n",
        "n_qubits = 12\n",
        "num_classes = len(classes)\n",
        "\n",
        "def create_hybrid_qnn(n_layers_var, fc1_hidden):\n",
        "    dev = qml.device(\"default.qubit\", wires=n_qubits)  # QNN on CPU\n",
        "\n",
        "    def variational(weights):\n",
        "        for layer in range(n_layers_var):\n",
        "            for q in range(n_qubits):\n",
        "                qml.Rot(weights[layer, q, 0], weights[layer, q, 1], weights[layer, q, 2], wires=q)\n",
        "            for q in range(n_qubits):\n",
        "                qml.CNOT(wires=[q, (q+1)%n_qubits])\n",
        "\n",
        "    @qml.qnode(dev, interface=\"torch\")\n",
        "    def qnode(inputs, weights):\n",
        "        qml.AngleEmbedding(inputs, wires=range(n_qubits), rotation=\"Y\")\n",
        "        variational(weights)\n",
        "        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "    weight_shapes = {\"weights\": (n_layers_var, n_qubits, 3)}\n",
        "    qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "\n",
        "    class HybridQNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.qnn = qlayer\n",
        "            self.fc1 = nn.Linear(n_qubits, fc1_hidden).to(device)\n",
        "            self.fc2 = nn.Linear(fc1_hidden, num_classes).to(device)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.qnn(x)             # QNN on CPU\n",
        "            x = x.to(device)            # move output to GPU\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = self.fc2(x)\n",
        "            return x\n",
        "\n",
        "    return HybridQNN()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxbzuOdlCZ47"
      },
      "outputs": [],
      "source": [
        "# Cell 8\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_model(model, train_loader, val_loader, lr, epochs=3, verbose=True):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor) # Assuming class_weights_tensor is defined globally\n",
        "\n",
        "    model.train()\n",
        "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        loader = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\") if verbose else train_loader\n",
        "\n",
        "        for i, batch in enumerate(loader):\n",
        "            Xb, yb = batch_to_device(batch, device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(Xb)\n",
        "            loss = criterion(out, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate training accuracy\n",
        "            preds = out.argmax(dim=1)\n",
        "            train_correct += (preds == yb).sum().item()\n",
        "            train_total += yb.size(0)\n",
        "\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        train_acc = train_correct / train_total\n",
        "        history[\"train_loss\"].append(avg_train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        val_loss, val_acc = evaluate_model_with_loss(model, val_loader, criterion)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Training finished.\")\n",
        "    return model, history\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            Xb, yb = batch_to_device(batch, device)\n",
        "            out = model(Xb)\n",
        "            preds = out.argmax(dim=1).cpu().numpy()\n",
        "            y_pred.extend(preds)\n",
        "            y_true.extend(yb.cpu().numpy())\n",
        "    acc = np.mean(np.array(y_pred) == np.array(y_true))\n",
        "    return acc\n",
        "\n",
        "def evaluate_model_with_loss(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            Xb, yb = batch_to_device(batch, device)\n",
        "            out = model(Xb)\n",
        "            loss = criterion(out, yb)\n",
        "            running_loss += loss.item()\n",
        "            preds = out.argmax(dim=1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1FLLF-mCb3h"
      },
      "outputs": [],
      "source": [
        "# Cell 9\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            Xb, yb = batch_to_device(batch, device)\n",
        "            out = model(Xb)\n",
        "            preds = out.argmax(dim=1).cpu().numpy()\n",
        "            y_pred.extend(preds)\n",
        "            y_true.extend(yb.cpu().numpy())\n",
        "    acc = np.mean(np.array(y_pred) == np.array(y_true))\n",
        "    return acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPkpvDlICdku",
        "outputId": "57208e1f-4334-462d-c6ed-1bae6d3a06ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 5000/5000 [06:09<00:00, 13.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.5063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 5000/5000 [06:11<00:00, 13.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.4755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 5000/5000 [06:07<00:00, 13.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.4676\n",
            "Training finished.\n",
            "Layers:1 FC:8 LR:0.005 BS:16 -> Test Acc: 0.8293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 2500/2500 [03:43<00:00, 11.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.5426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 2500/2500 [03:44<00:00, 11.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.5030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 2500/2500 [03:39<00:00, 11.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.4899\n",
            "Training finished.\n",
            "Layers:1 FC:8 LR:0.005 BS:32 -> Test Acc: 0.7423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 5000/5000 [05:56<00:00, 14.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 5000/5000 [06:04<00:00, 13.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.4471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 5000/5000 [06:00<00:00, 13.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.4365\n",
            "Training finished.\n",
            "Layers:1 FC:8 LR:0.01 BS:16 -> Test Acc: 0.8394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 2500/2500 [03:42<00:00, 11.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 2500/2500 [03:45<00:00, 11.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.4561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 2500/2500 [03:47<00:00, 11.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.4534\n",
            "Training finished.\n",
            "Layers:1 FC:8 LR:0.01 BS:32 -> Test Acc: 0.8387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 5000/5000 [06:04<00:00, 13.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 5000/5000 [06:01<00:00, 13.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.4453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 5000/5000 [05:59<00:00, 13.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.4328\n",
            "Training finished.\n",
            "Layers:1 FC:16 LR:0.005 BS:16 -> Test Acc: 0.8487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 2500/2500 [03:42<00:00, 11.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 2500/2500 [03:41<00:00, 11.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.4525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 2500/2500 [03:47<00:00, 10.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.4388\n",
            "Training finished.\n",
            "Layers:1 FC:16 LR:0.005 BS:32 -> Test Acc: 0.8326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 5000/5000 [05:58<00:00, 13.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 5000/5000 [06:01<00:00, 13.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 5000/5000 [06:06<00:00, 13.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.3762\n",
            "Training finished.\n",
            "Layers:1 FC:16 LR:0.01 BS:16 -> Test Acc: 0.8617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 2500/2500 [03:42<00:00, 11.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 2500/2500 [03:41<00:00, 11.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.4556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 2500/2500 [03:37<00:00, 11.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.4456\n",
            "Training finished.\n",
            "Layers:1 FC:16 LR:0.01 BS:32 -> Test Acc: 0.8366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 5000/5000 [09:28<00:00,  8.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 5000/5000 [09:31<00:00,  8.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 5000/5000 [09:43<00:00,  8.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.3409\n",
            "Training finished.\n",
            "Layers:2 FC:8 LR:0.005 BS:16 -> Test Acc: 0.8628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 2500/2500 [06:15<00:00,  6.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 2500/2500 [06:16<00:00,  6.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 2500/2500 [06:14<00:00,  6.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.3580\n",
            "Training finished.\n",
            "Layers:2 FC:8 LR:0.005 BS:32 -> Test Acc: 0.8543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 5000/5000 [09:47<00:00,  8.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 5000/5000 [09:45<00:00,  8.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 5000/5000 [09:44<00:00,  8.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.3614\n",
            "Training finished.\n",
            "Layers:2 FC:8 LR:0.01 BS:16 -> Test Acc: 0.8694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 2500/2500 [06:14<00:00,  6.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 2500/2500 [06:16<00:00,  6.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3:  59%|█████▉    | 1476/2500 [03:36<02:26,  6.99it/s]"
          ]
        }
      ],
      "source": [
        "# Cell 10\n",
        "tuning_grid = {\n",
        "    \"n_layers_var\": [1, 2],\n",
        "    \"fc1_hidden\": [8, 16],\n",
        "    \"lr\": [0.005, 0.01],\n",
        "    \"batch_size\": [16, 32]\n",
        "}\n",
        "\n",
        "best_acc = 0\n",
        "best_config = None\n",
        "\n",
        "for n_layers_var in tuning_grid[\"n_layers_var\"]:\n",
        "    for fc1_hidden in tuning_grid[\"fc1_hidden\"]:\n",
        "        for lr in tuning_grid[\"lr\"]:\n",
        "            for batch_size in tuning_grid[\"batch_size\"]:\n",
        "                train_loader = DataLoader(TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
        "                                                        torch.tensor(y_train, dtype=torch.long)),\n",
        "                                          batch_size=batch_size, shuffle=True)\n",
        "\n",
        "                model = create_hybrid_qnn(n_layers_var, fc1_hidden)\n",
        "                model_trained = train_model(model, train_loader, lr, epochs=3, verbose=True)\n",
        "\n",
        "                acc = evaluate_model(model_trained, test_loader)\n",
        "                print(f\"Layers:{n_layers_var} FC:{fc1_hidden} LR:{lr} BS:{batch_size} -> Test Acc: {acc:.4f}\")\n",
        "\n",
        "                if acc > best_acc:\n",
        "                    best_acc = acc\n",
        "                    best_config = {\"n_layers_var\": n_layers_var,\n",
        "                                   \"fc1_hidden\": fc1_hidden,\n",
        "                                   \"lr\": lr,\n",
        "                                   \"batch_size\": batch_size}\n",
        "\n",
        "print(\"Best hyperparameters:\", best_config, \"with test accuracy:\", best_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soRChj98DOoo",
        "outputId": "ea654869-e11b-4e6c-826a-7e1a29a2f0f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 5000/5000 [10:13<00:00,  8.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 5000/5000 [10:00<00:00,  8.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3746\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 5000/5000 [10:06<00:00,  8.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.3617\n",
            "Training finished.\n",
            "Layers:2 FC:8 LR:0.005 BS:16 -> Test Acc: 0.8620\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 2500/2500 [06:30<00:00,  6.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 2500/2500 [06:18<00:00,  6.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 2500/2500 [06:21<00:00,  6.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.3282\n",
            "Training finished.\n",
            "Layers:2 FC:8 LR:0.005 BS:32 -> Test Acc: 0.8385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 5000/5000 [09:51<00:00,  8.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 5000/5000 [10:03<00:00,  8.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 5000/5000 [10:15<00:00,  8.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.3527\n",
            "Training finished.\n",
            "Layers:2 FC:8 LR:0.01 BS:16 -> Test Acc: 0.8772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 2500/2500 [06:26<00:00,  6.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 2500/2500 [06:20<00:00,  6.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 2500/2500 [06:13<00:00,  6.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.3402\n",
            "Training finished.\n",
            "Layers:2 FC:8 LR:0.01 BS:32 -> Test Acc: 0.8686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 5000/5000 [09:43<00:00,  8.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 5000/5000 [09:44<00:00,  8.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 5000/5000 [09:51<00:00,  8.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.3575\n",
            "Training finished.\n",
            "Layers:2 FC:16 LR:0.005 BS:16 -> Test Acc: 0.8608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 2500/2500 [06:17<00:00,  6.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 2500/2500 [06:20<00:00,  6.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 2500/2500 [06:19<00:00,  6.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.3557\n",
            "Training finished.\n",
            "Layers:2 FC:16 LR:0.005 BS:32 -> Test Acc: 0.8710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 5000/5000 [09:47<00:00,  8.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.3986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 5000/5000 [09:41<00:00,  8.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 5000/5000 [10:05<00:00,  8.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.3399\n",
            "Training finished.\n",
            "Layers:2 FC:16 LR:0.01 BS:16 -> Test Acc: 0.8821\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 2500/2500 [06:12<00:00,  6.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3] - Average Loss: 0.4258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 2500/2500 [06:12<00:00,  6.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/3] - Average Loss: 0.3744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 2500/2500 [06:07<00:00,  6.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/3] - Average Loss: 0.3648\n",
            "Training finished.\n",
            "Layers:2 FC:16 LR:0.01 BS:32 -> Test Acc: 0.8390\n",
            "Best hyperparameters: {'n_layers_var': 2, 'fc1_hidden': 16, 'lr': 0.01, 'batch_size': 16} with test accuracy: 0.88205\n"
          ]
        }
      ],
      "source": [
        "# Cell 10\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "tuning_grid = {\n",
        "    \"n_layers_var\": [2],\n",
        "    \"fc1_hidden\": [8, 16],\n",
        "    \"lr\": [0.005, 0.01],\n",
        "    \"batch_size\": [16, 32]\n",
        "}\n",
        "\n",
        "best_acc = 0\n",
        "best_config = None\n",
        "\n",
        "for n_layers_var in tuning_grid[\"n_layers_var\"]:\n",
        "    for fc1_hidden in tuning_grid[\"fc1_hidden\"]:\n",
        "        for lr in tuning_grid[\"lr\"]:\n",
        "            for batch_size in tuning_grid[\"batch_size\"]:\n",
        "                train_loader = DataLoader(TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
        "                                                        torch.tensor(y_train, dtype=torch.long)),\n",
        "                                          batch_size=batch_size, shuffle=True)\n",
        "\n",
        "                model = create_hybrid_qnn(n_layers_var, fc1_hidden)\n",
        "                model_trained = train_model(model, train_loader, lr, epochs=3, verbose=True)\n",
        "\n",
        "                acc = evaluate_model(model_trained, test_loader)\n",
        "                print(f\"Layers:{n_layers_var} FC:{fc1_hidden} LR:{lr} BS:{batch_size} -> Test Acc: {acc:.4f}\")\n",
        "\n",
        "                if acc > best_acc:\n",
        "                    best_acc = acc\n",
        "                    best_config = {\"n_layers_var\": n_layers_var,\n",
        "                                   \"fc1_hidden\": fc1_hidden,\n",
        "                                   \"lr\": lr,\n",
        "                                   \"batch_size\": batch_size}\n",
        "\n",
        "print(\"Best hyperparameters:\", best_config, \"with test accuracy:\", best_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIqwvnqnUEGh"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "n_clients = 5\n",
        "rounds = 3\n",
        "best_hyperparams = {'n_layers_var': 2, 'fc1_hidden': 16, 'lr': 0.01, 'batch_size': 16}\n",
        "\n",
        "# Split dataset into clients\n",
        "client_data = []\n",
        "indices = np.array_split(np.arange(len(X_train)), n_clients)\n",
        "for idx in indices:\n",
        "    client_X = X_train[idx]\n",
        "    client_y = y_train[idx]\n",
        "    loader = DataLoader(TensorDataset(torch.tensor(client_X, dtype=torch.float32),\n",
        "                                      torch.tensor(client_y, dtype=torch.long)),\n",
        "                        batch_size=best_hyperparams['batch_size'], shuffle=True)\n",
        "    client_data.append(loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUFdfGVm5q1s"
      },
      "outputs": [],
      "source": [
        "def apply_dp_gradients(model, max_norm=1.0, noise_multiplier=0.1):\n",
        "    for param in model.parameters():\n",
        "        if param.grad is not None:\n",
        "            # Clip gradient\n",
        "            torch.nn.utils.clip_grad_norm_([param], max_norm)\n",
        "            # Add Gaussian noise\n",
        "            param.grad += torch.randn_like(param.grad) * noise_multiplier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfLf96Pi5s0C"
      },
      "outputs": [],
      "source": [
        "def federated_train(model_fn, client_loaders, rounds, device, lr=0.01, dp=True):\n",
        "    global_model = model_fn().to(device)\n",
        "\n",
        "    for r in range(rounds):\n",
        "        print(f\"\\n--- Round {r+1}/{rounds} ---\")\n",
        "        local_weights = []\n",
        "\n",
        "        for i, loader in enumerate(client_loaders):\n",
        "            local_model = model_fn().to(device)\n",
        "            local_model.load_state_dict(global_model.state_dict())  # Start from global model\n",
        "            optimizer = torch.optim.Adam(local_model.parameters(), lr=lr)\n",
        "            local_model.train()\n",
        "\n",
        "            for Xb, yb in loader:\n",
        "                Xb, yb = batch_to_device((Xb, yb), device)\n",
        "                optimizer.zero_grad()\n",
        "                out = local_model(Xb)\n",
        "                loss = criterion(out, yb)\n",
        "                loss.backward()\n",
        "\n",
        "                if dp:\n",
        "                    apply_dp_gradients(local_model)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "            local_weights.append({k: v.cpu() for k, v in local_model.state_dict().items()})\n",
        "            print(f\"Client {i+1} done\")\n",
        "\n",
        "        # Federated averaging\n",
        "        global_dict = global_model.state_dict()\n",
        "        for key in global_dict.keys():\n",
        "            global_dict[key] = torch.stack([w[key] for w in local_weights], 0).mean(0)\n",
        "        global_model.load_state_dict(global_dict)\n",
        "\n",
        "        # Optional: evaluate on full test set after each round\n",
        "        acc = evaluate_model(global_model, test_loader)\n",
        "        print(f\"Round {r+1} Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "    return global_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN7vIT3_Yh41"
      },
      "outputs": [],
      "source": [
        "# Model factory\n",
        "def model_factory():\n",
        "    return create_hybrid_qnn(best_hyperparams['n_layers_var'], best_hyperparams['fc1_hidden'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOVHojou5vQ1",
        "outputId": "4b9bcebc-28bc-43ec-ede8-0bf3e35efaf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Round 1/3 ---\n",
            "Client 1 done\n",
            "Client 2 done\n",
            "Client 3 done\n",
            "Client 4 done\n",
            "Client 5 done\n",
            "Round 1 Test Accuracy: 0.7781\n",
            "\n",
            "--- Round 2/3 ---\n",
            "Client 1 done\n",
            "Client 2 done\n",
            "Client 3 done\n",
            "Client 4 done\n",
            "Client 5 done\n",
            "Round 2 Test Accuracy: 0.8021\n",
            "\n",
            "--- Round 3/3 ---\n",
            "Client 1 done\n",
            "Client 2 done\n",
            "Client 3 done\n",
            "Client 4 done\n",
            "Client 5 done\n",
            "Round 3 Test Accuracy: 0.8182\n"
          ]
        }
      ],
      "source": [
        "global_model = federated_train(model_factory, client_data, rounds=rounds, device=device, lr=best_hyperparams['lr'], dp=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so48SSX6ekWy",
        "outputId": "0fec609d-52c2-4b48-c6ec-7034b7a5a570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Round 1/5 ---\n",
            "Client 1 done\n",
            "Client 2 done\n",
            "Client 3 done\n",
            "Client 4 done\n",
            "Client 5 done\n",
            "Round 1 Test Accuracy: 0.7227\n",
            "\n",
            "--- Round 2/5 ---\n",
            "Client 1 done\n",
            "Client 2 done\n",
            "Client 3 done\n",
            "Client 4 done\n",
            "Client 5 done\n",
            "Round 2 Test Accuracy: 0.7427\n",
            "\n",
            "--- Round 3/5 ---\n",
            "Client 1 done\n",
            "Client 2 done\n",
            "Client 3 done\n",
            "Client 4 done\n",
            "Client 5 done\n",
            "Round 3 Test Accuracy: 0.8119\n",
            "\n",
            "--- Round 4/5 ---\n",
            "Client 1 done\n",
            "Client 2 done\n",
            "Client 3 done\n",
            "Client 4 done\n",
            "Client 5 done\n",
            "Round 4 Test Accuracy: 0.8275\n",
            "\n",
            "--- Round 5/5 ---\n",
            "Client 1 done\n",
            "Client 2 done\n",
            "Client 3 done\n",
            "Client 4 done\n",
            "Client 5 done\n",
            "Round 5 Test Accuracy: 0.8337\n"
          ]
        }
      ],
      "source": [
        "global_model = federated_train(model_factory, client_data, rounds=5, device=device, lr=best_hyperparams['lr'], dp=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "narCEDQntu7C",
        "outputId": "e76fdfe4-4224-4ae2-8f3e-cd763de52bec"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'federated_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3434149147.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglobal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfederated_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_hyperparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'federated_train' is not defined"
          ]
        }
      ],
      "source": [
        "global_model = federated_train(model_factory, client_data, rounds=10, device=device, lr=best_hyperparams['lr'], dp=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5nrN8wFCSmX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ouNy3gkDboD"
      },
      "outputs": [],
      "source": [
        "def client_classification_report(model, client_loaders, device, classes, description=\"\"):\n",
        "    print(f\"\\n=== Classification Report {description} ===\")\n",
        "\n",
        "    for i, loader in enumerate(client_loaders):\n",
        "        y_true, y_pred = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for Xb, yb in loader:\n",
        "                Xb, yb = batch_to_device((Xb, yb), device)\n",
        "                out = model(Xb)\n",
        "                preds = out.argmax(dim=1).cpu().numpy()\n",
        "                y_pred.extend(preds)\n",
        "                y_true.extend(yb.cpu().numpy())\n",
        "        print(f\"\\n--- Client {i+1} ---\")\n",
        "        print(classification_report(y_true, y_pred, labels=classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMM1FLo0DhqL"
      },
      "outputs": [],
      "source": [
        "# Create fresh untrained models for \"before\" evaluation\n",
        "before_models = [model_factory().to(device) for _ in range(n_clients)]\n",
        "\n",
        "# Evaluate each client separately using initial weights (same as global model before training)\n",
        "for i in range(n_clients):\n",
        "    before_models[i].load_state_dict(model_factory().state_dict())  # Untrained global model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "774NTX-xDjlf",
        "outputId": "1fa3b40c-9694-4119-fcc6-f48e523e881e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Classification Report Before FedQNN Training ===\n",
            "\n",
            "--- Client 1 ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4373\n",
            "           1       0.73      1.00      0.84     11627\n",
            "\n",
            "    accuracy                           0.73     16000\n",
            "   macro avg       0.36      0.50      0.42     16000\n",
            "weighted avg       0.53      0.73      0.61     16000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Client 2 ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4356\n",
            "           1       0.73      1.00      0.84     11644\n",
            "\n",
            "    accuracy                           0.73     16000\n",
            "   macro avg       0.36      0.50      0.42     16000\n",
            "weighted avg       0.53      0.73      0.61     16000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Client 3 ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4433\n",
            "           1       0.72      1.00      0.84     11567\n",
            "\n",
            "    accuracy                           0.72     16000\n",
            "   macro avg       0.36      0.50      0.42     16000\n",
            "weighted avg       0.52      0.72      0.61     16000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Client 4 ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4397\n",
            "           1       0.73      1.00      0.84     11603\n",
            "\n",
            "    accuracy                           0.73     16000\n",
            "   macro avg       0.36      0.50      0.42     16000\n",
            "weighted avg       0.53      0.73      0.61     16000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Client 5 ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4374\n",
            "           1       0.73      1.00      0.84     11626\n",
            "\n",
            "    accuracy                           0.73     16000\n",
            "   macro avg       0.36      0.50      0.42     16000\n",
            "weighted avg       0.53      0.73      0.61     16000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "client_classification_report(model_factory(), client_data, device, classes, description=\"Before FedQNN Training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TQoqklUDmNB",
        "outputId": "1fd6eec7-cce0-4580-d345-27f319e4c0c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Classification Report After FedQNN Training ===\n",
            "\n",
            "--- Client 1 ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.76      0.69      4373\n",
            "           1       0.90      0.84      0.87     11627\n",
            "\n",
            "    accuracy                           0.82     16000\n",
            "   macro avg       0.77      0.80      0.78     16000\n",
            "weighted avg       0.83      0.82      0.82     16000\n",
            "\n",
            "\n",
            "--- Client 2 ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.77      0.70      4356\n",
            "           1       0.91      0.84      0.87     11644\n",
            "\n",
            "    accuracy                           0.82     16000\n",
            "   macro avg       0.78      0.81      0.79     16000\n",
            "weighted avg       0.84      0.82      0.83     16000\n",
            "\n",
            "\n",
            "--- Client 3 ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.77      0.70      4433\n",
            "           1       0.90      0.84      0.87     11567\n",
            "\n",
            "    accuracy                           0.82     16000\n",
            "   macro avg       0.77      0.80      0.78     16000\n",
            "weighted avg       0.83      0.82      0.82     16000\n",
            "\n",
            "\n",
            "--- Client 4 ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.77      0.70      4397\n",
            "           1       0.91      0.84      0.87     11603\n",
            "\n",
            "    accuracy                           0.82     16000\n",
            "   macro avg       0.78      0.81      0.79     16000\n",
            "weighted avg       0.84      0.82      0.83     16000\n",
            "\n",
            "\n",
            "--- Client 5 ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.77      0.70      4374\n",
            "           1       0.91      0.84      0.87     11626\n",
            "\n",
            "    accuracy                           0.82     16000\n",
            "   macro avg       0.78      0.81      0.79     16000\n",
            "weighted avg       0.84      0.82      0.83     16000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "client_classification_report(global_model, client_data, device, classes, description=\"After FedQNN Training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZA0iyWSGRjH",
        "outputId": "cfd1b59d-3590-4490-bc45-4ddac13aed23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Global Model Before FedQNN Training ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      1.00      0.43      5483\n",
            "           1       0.00      0.00      0.00     14517\n",
            "\n",
            "    accuracy                           0.27     20000\n",
            "   macro avg       0.14      0.50      0.22     20000\n",
            "weighted avg       0.08      0.27      0.12     20000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Create a fresh global model (same as used before training)\n",
        "global_model_before = model_factory().to(device)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "global_model_before.eval()\n",
        "with torch.no_grad():\n",
        "    for Xb, yb in test_loader:\n",
        "        Xb, yb = batch_to_device((Xb, yb), device)\n",
        "        out = global_model_before(Xb)\n",
        "        preds = out.argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(yb.cpu().numpy())\n",
        "\n",
        "print(\"=== Global Model Before FedQNN Training ===\")\n",
        "print(classification_report(y_true, y_pred, labels=classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHko3DuAGTgq",
        "outputId": "55d8e3ab-7a3b-417a-b89b-e6b3ddad241a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Global Model After FedQNN Training ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.76      0.70      5483\n",
            "           1       0.90      0.84      0.87     14517\n",
            "\n",
            "    accuracy                           0.82     20000\n",
            "   macro avg       0.77      0.80      0.78     20000\n",
            "weighted avg       0.83      0.82      0.82     20000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_true, y_pred = [], []\n",
        "\n",
        "global_model.eval()\n",
        "with torch.no_grad():\n",
        "    for Xb, yb in test_loader:\n",
        "        Xb, yb = batch_to_device((Xb, yb), device)\n",
        "        out = global_model(Xb)\n",
        "        preds = out.argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(yb.cpu().numpy())\n",
        "\n",
        "print(\"=== Global Model After FedQNN Training ===\")\n",
        "print(classification_report(y_true, y_pred, labels=classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kqdXGSTIFUQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def client_seen_unseen_report(model, client_loaders, device, description=\"\"):\n",
        "    print(f\"\\n=== {description} ===\")\n",
        "\n",
        "    for i, loader in enumerate(client_loaders):\n",
        "        y_true, y_pred = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for Xb, yb in loader:\n",
        "                Xb, yb = batch_to_device((Xb, yb), device)\n",
        "                out = model(Xb)\n",
        "                preds = out.argmax(dim=1).cpu().numpy()\n",
        "                y_pred.extend(preds)\n",
        "                y_true.extend(yb.cpu().numpy())\n",
        "\n",
        "        seen, unseen = get_seen_unseen(y_true, y_pred, i)\n",
        "\n",
        "        print(f\"\\n--- Client {i+1} ---\")\n",
        "        print(\"Seen Attacks:\")\n",
        "        print(classification_report(y_true, y_pred, labels=list(seen)))\n",
        "        print(\"Unseen Attacks:\")\n",
        "        if unseen:\n",
        "            print(classification_report(y_true, y_pred, labels=list(unseen)))\n",
        "        else:\n",
        "            print(\"No unseen attacks for this client\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AscWLGlUIPgD",
        "outputId": "5e7ef30e-8835-4bdf-e224-bfc90173eaf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Before FedQNN Training ===\n",
            "\n",
            "--- Client 1 ---\n",
            "Seen Attacks:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4373\n",
            "           1       0.73      1.00      0.84     11627\n",
            "\n",
            "    accuracy                           0.73     16000\n",
            "   macro avg       0.36      0.50      0.42     16000\n",
            "weighted avg       0.53      0.73      0.61     16000\n",
            "\n",
            "Unseen Attacks:\n",
            "No unseen attacks for this client\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Client 2 ---\n",
            "Seen Attacks:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4356\n",
            "           1       0.73      1.00      0.84     11644\n",
            "\n",
            "    accuracy                           0.73     16000\n",
            "   macro avg       0.36      0.50      0.42     16000\n",
            "weighted avg       0.53      0.73      0.61     16000\n",
            "\n",
            "Unseen Attacks:\n",
            "No unseen attacks for this client\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Client 3 ---\n",
            "Seen Attacks:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4433\n",
            "           1       0.72      1.00      0.84     11567\n",
            "\n",
            "    accuracy                           0.72     16000\n",
            "   macro avg       0.36      0.50      0.42     16000\n",
            "weighted avg       0.52      0.72      0.61     16000\n",
            "\n",
            "Unseen Attacks:\n",
            "No unseen attacks for this client\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Client 4 ---\n",
            "Seen Attacks:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4397\n",
            "           1       0.73      1.00      0.84     11603\n",
            "\n",
            "    accuracy                           0.73     16000\n",
            "   macro avg       0.36      0.50      0.42     16000\n",
            "weighted avg       0.53      0.73      0.61     16000\n",
            "\n",
            "Unseen Attacks:\n",
            "No unseen attacks for this client\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Client 5 ---\n",
            "Seen Attacks:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4374\n",
            "           1       0.73      1.00      0.84     11626\n",
            "\n",
            "    accuracy                           0.73     16000\n",
            "   macro avg       0.36      0.50      0.42     16000\n",
            "weighted avg       0.53      0.73      0.61     16000\n",
            "\n",
            "Unseen Attacks:\n",
            "No unseen attacks for this client\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "client_seen_unseen_report(model_factory(), client_data, device, description=\"Before FedQNN Training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4WYCK8PIRcP",
        "outputId": "08e91145-593b-4c53-97bd-624cfa3ff749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== After FedQNN Training ===\n",
            "\n",
            "--- Client 1 ---\n",
            "Seen Attacks:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.76      0.69      4373\n",
            "           1       0.90      0.84      0.87     11627\n",
            "\n",
            "    accuracy                           0.82     16000\n",
            "   macro avg       0.77      0.80      0.78     16000\n",
            "weighted avg       0.83      0.82      0.82     16000\n",
            "\n",
            "Unseen Attacks:\n",
            "No unseen attacks for this client\n",
            "\n",
            "--- Client 2 ---\n",
            "Seen Attacks:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.77      0.70      4356\n",
            "           1       0.91      0.84      0.87     11644\n",
            "\n",
            "    accuracy                           0.82     16000\n",
            "   macro avg       0.78      0.81      0.79     16000\n",
            "weighted avg       0.84      0.82      0.83     16000\n",
            "\n",
            "Unseen Attacks:\n",
            "No unseen attacks for this client\n",
            "\n",
            "--- Client 3 ---\n",
            "Seen Attacks:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.77      0.70      4433\n",
            "           1       0.90      0.84      0.87     11567\n",
            "\n",
            "    accuracy                           0.82     16000\n",
            "   macro avg       0.77      0.80      0.78     16000\n",
            "weighted avg       0.83      0.82      0.82     16000\n",
            "\n",
            "Unseen Attacks:\n",
            "No unseen attacks for this client\n",
            "\n",
            "--- Client 4 ---\n",
            "Seen Attacks:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.77      0.70      4397\n",
            "           1       0.91      0.84      0.87     11603\n",
            "\n",
            "    accuracy                           0.82     16000\n",
            "   macro avg       0.78      0.81      0.79     16000\n",
            "weighted avg       0.84      0.82      0.83     16000\n",
            "\n",
            "Unseen Attacks:\n",
            "No unseen attacks for this client\n",
            "\n",
            "--- Client 5 ---\n",
            "Seen Attacks:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.77      0.70      4374\n",
            "           1       0.91      0.84      0.87     11626\n",
            "\n",
            "    accuracy                           0.82     16000\n",
            "   macro avg       0.78      0.81      0.79     16000\n",
            "weighted avg       0.84      0.82      0.83     16000\n",
            "\n",
            "Unseen Attacks:\n",
            "No unseen attacks for this client\n"
          ]
        }
      ],
      "source": [
        "client_seen_unseen_report(global_model, client_data, device, description=\"After FedQNN Training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38R2F7ZcITeB",
        "outputId": "b28c6119-a06a-4049-917f-ad9cdbd75c7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.94529362e+00 -1.38085651e+00 -2.50262658e-01  6.69346535e-01\n",
            "   4.73139760e-01 -1.12968948e+00  1.21173417e+00  8.57921520e-01\n",
            "   1.85925696e-01  8.88823750e-02 -2.22233683e-02  5.73551146e-01]\n",
            " [-2.64042908e+00  2.50419504e-01 -1.03785814e+00 -3.96521344e-01\n",
            "  -1.72508375e+00  4.29173451e-01 -1.95576691e-01 -6.35014618e-01\n",
            "  -6.30823395e-02  2.25009764e-02  6.91065682e-02  2.05373530e-01]\n",
            " [-1.67492670e+00 -2.72144015e-01 -1.13939821e+00 -1.08120825e-01\n",
            "  -1.38523000e+00 -3.77471482e-01 -2.72492876e-01 -3.63326288e-01\n",
            "  -1.11945589e-01  5.89882466e-01 -1.31583049e-01  1.00166369e+00]\n",
            " [ 2.92052184e-01 -1.22111828e+00 -8.25567722e-01  3.05787613e-01\n",
            "   5.07863416e-01 -8.49677728e-01  2.21302700e-01  1.06832920e+00\n",
            "   3.23845034e-01 -2.73673471e-01  1.45053161e-01  2.91073270e-01]\n",
            " [-2.89814368e+00  1.12446145e+00  2.40144260e+00  1.15359604e-02\n",
            "   1.50625130e+00 -6.95319223e-02 -1.95755140e-02 -4.15349461e-02\n",
            "  -3.79883783e-02  1.81759436e-03 -1.30689819e-01  2.01603096e-02]]\n"
          ]
        }
      ],
      "source": [
        "# Print first 5 rows\n",
        "print(X_pca[:5, :])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddl_3WChMmsV"
      },
      "outputs": [],
      "source": [
        "def apply_dp_gradients(model, max_norm=1.0, noise_multiplier=0.1, device='cpu'):\n",
        "    \"\"\"\n",
        "    Apply Differential Privacy to gradients:\n",
        "    - Clips gradients per parameter\n",
        "    - Adds Gaussian noise\n",
        "    This is a simple DP mechanism suitable for federated learning.\n",
        "    \"\"\"\n",
        "    for param in model.parameters():\n",
        "        if param.grad is not None:\n",
        "            # Clip gradient per parameter\n",
        "            param_norm = param.grad.data.norm(2)\n",
        "            clip_coef = max_norm / (param_norm + 1e-6)\n",
        "            if clip_coef < 1:\n",
        "                param.grad.data.mul_(clip_coef)\n",
        "\n",
        "            # Add Gaussian noise\n",
        "            noise = torch.randn_like(param.grad).to(device) * noise_multiplier\n",
        "            param.grad.data.add_(noise)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ_H0P_GXdi0"
      },
      "outputs": [],
      "source": [
        "def federated_train(model_fn, client_loaders, rounds, device, lr=0.01, dp=True):\n",
        "    global_model = model_fn().to(device)\n",
        "\n",
        "    for r in range(rounds):\n",
        "        print(f\"\\n--- Round {r+1}/{rounds} ---\")\n",
        "        local_weights = []\n",
        "\n",
        "        for i, loader in enumerate(client_loaders):\n",
        "            local_model = model_fn().to(device)\n",
        "            local_model.load_state_dict(global_model.state_dict())  # Start from global model\n",
        "            optimizer = torch.optim.Adam(local_model.parameters(), lr=lr)\n",
        "            local_model.train()\n",
        "\n",
        "            for Xb, yb in loader:\n",
        "                Xb, yb = batch_to_device((Xb, yb), device)\n",
        "                optimizer.zero_grad()\n",
        "                out = local_model(Xb)\n",
        "                loss = criterion(out, yb)\n",
        "                loss.backward()\n",
        "\n",
        "                if dp:\n",
        "                    apply_dp_gradients(local_model, max_norm=1.0, noise_multiplier=0.1, device=device)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "            local_weights.append({k: v.cpu() for k, v in local_model.state_dict().items()})\n",
        "            print(f\"Client {i+1} done\")\n",
        "\n",
        "        # Federated averaging\n",
        "        global_dict = global_model.state_dict()\n",
        "        for key in global_dict.keys():\n",
        "            global_dict[key] = torch.stack([w[key] for w in local_weights], 0).mean(0)\n",
        "        global_model.load_state_dict(global_dict)\n",
        "\n",
        "        # Optional: evaluate on full test set after each round\n",
        "        acc = evaluate_model(global_model, test_loader)\n",
        "        print(f\"Round {r+1} Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "    return global_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "wQE-mfa7Xyq8",
        "outputId": "f552d083-ffca-4916-a4d5-614dd698418a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model_factory' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1213284417.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglobal_model_dp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfederated_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_hyperparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_factory' is not defined"
          ]
        }
      ],
      "source": [
        "global_model_dp = federated_train(model_factory, client_data, rounds=rounds, device=device, lr=best_hyperparams['lr'], dp=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7s4RZddlyHR"
      },
      "outputs": [],
      "source": [
        "def federated_train(model_fn, client_loaders, rounds, device, lr=0.01, dp=True, initial_model=None, return_history=True):\n",
        "    \"\"\"\n",
        "    Federated training with optional DP, continued training, and round-wise history logging.\n",
        "\n",
        "    Args:\n",
        "        model_fn: function that returns a new model instance\n",
        "        client_loaders: list of DataLoaders for each client\n",
        "        rounds: number of federated rounds\n",
        "        device: torch device\n",
        "        lr: learning rate\n",
        "        dp: whether to apply differential privacy\n",
        "        initial_model: optional pre-trained global model to continue training\n",
        "        return_history: whether to return round-wise accuracy and loss\n",
        "    Returns:\n",
        "        global_model: trained global model\n",
        "        history (optional): dict containing round-wise accuracy and optionally loss\n",
        "    \"\"\"\n",
        "    # Initialize model\n",
        "    if initial_model is not None:\n",
        "        global_model = initial_model.to(device)\n",
        "    else:\n",
        "        global_model = model_fn().to(device)\n",
        "\n",
        "    history = {\n",
        "        \"round\": [],\n",
        "        \"test_acc\": [],\n",
        "        \"client_train_acc\": []\n",
        "    }\n",
        "\n",
        "    for r in range(rounds):\n",
        "        print(f\"\\n--- Round {r+1}/{rounds} ---\")\n",
        "        local_weights = []\n",
        "        round_client_acc = []\n",
        "\n",
        "        for i, loader in enumerate(client_loaders):\n",
        "            local_model = model_fn().to(device)\n",
        "            local_model.load_state_dict(global_model.state_dict())  # Start from current global model\n",
        "            optimizer = torch.optim.Adam(local_model.parameters(), lr=lr)\n",
        "            local_model.train()\n",
        "\n",
        "            for Xb, yb in loader:\n",
        "                Xb, yb = batch_to_device((Xb, yb), device)\n",
        "                optimizer.zero_grad()\n",
        "                out = local_model(Xb)\n",
        "                loss = criterion(out, yb)\n",
        "                loss.backward()\n",
        "\n",
        "                if dp:\n",
        "                    apply_dp_gradients(local_model, max_norm=1.0, noise_multiplier=0.1, device=device)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "            # Save local model weights (CPU to save memory)\n",
        "            local_weights.append({k: v.cpu() for k, v in local_model.state_dict().items()})\n",
        "\n",
        "            # Optional: compute training accuracy for this client\n",
        "            client_acc = evaluate_model(local_model, loader)\n",
        "            round_client_acc.append(client_acc)\n",
        "            print(f\"Client {i+1} done - Train Acc: {client_acc:.4f}\")\n",
        "\n",
        "        # Federated averaging\n",
        "        global_dict = global_model.state_dict()\n",
        "        for key in global_dict.keys():\n",
        "            global_dict[key] = torch.stack([w[key] for w in local_weights], 0).mean(0)\n",
        "        global_model.load_state_dict(global_dict)\n",
        "\n",
        "        # Evaluate on global test set\n",
        "        test_acc = evaluate_model(global_model, test_loader)\n",
        "        print(f\"Round {r+1} Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "        # Save history\n",
        "        history[\"round\"].append(r+1)\n",
        "        history[\"test_acc\"].append(test_acc)\n",
        "        history[\"client_train_acc\"].append(round_client_acc)\n",
        "\n",
        "    if return_history:\n",
        "        return global_model, history\n",
        "    else:\n",
        "        return global_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRb2Ddmwl05x",
        "outputId": "ab327fc0-ecd0-4a2a-ec3b-6b43a62e1d43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Round 1/3 ---\n",
            "Client 1 done - Train Acc: 0.4774\n",
            "Client 2 done - Train Acc: 0.4918\n",
            "Client 3 done - Train Acc: 0.4884\n",
            "Client 4 done - Train Acc: 0.4575\n",
            "Client 5 done - Train Acc: 0.5332\n",
            "Round 1 Test Accuracy: 0.4009\n",
            "\n",
            "--- Round 2/3 ---\n",
            "Client 1 done - Train Acc: 0.5385\n",
            "Client 2 done - Train Acc: 0.5263\n",
            "Client 3 done - Train Acc: 0.5072\n",
            "Client 4 done - Train Acc: 0.5548\n",
            "Client 5 done - Train Acc: 0.5136\n",
            "Round 2 Test Accuracy: 0.5087\n",
            "\n",
            "--- Round 3/3 ---\n",
            "Client 1 done - Train Acc: 0.5652\n",
            "Client 2 done - Train Acc: 0.5935\n",
            "Client 3 done - Train Acc: 0.5960\n",
            "Client 4 done - Train Acc: 0.5887\n",
            "Client 5 done - Train Acc: 0.5706\n",
            "Round 3 Test Accuracy: 0.5701\n"
          ]
        }
      ],
      "source": [
        "global_model_dp, history1 = federated_train(\n",
        "    model_fn=model_factory,\n",
        "    client_loaders=client_data,\n",
        "    rounds=3,\n",
        "    device=device,\n",
        "    lr=best_hyperparams['lr'],\n",
        "    dp=True\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
